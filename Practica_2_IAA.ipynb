{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practica 2 IAA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNbzFTdTKoGK8uX/Iw+zoIm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/p82maavd/IAA/blob/main/Practica_2_IAA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basic Dataset**"
      ],
      "metadata": {
        "id": "M2c4WZxKzZVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install turicreate"
      ],
      "metadata": {
        "id": "cvxfY-avb5mC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "95b64bf9-6be5-4703-8af2-6c02a5b1d0bd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting turicreate\n",
            "  Downloading turicreate-6.4.1-cp37-cp37m-manylinux1_x86_64.whl (92.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 92.0 MB 14 kB/s \n",
            "\u001b[?25hCollecting numba<0.51.0\n",
            "  Downloading numba-0.50.1-cp37-cp37m-manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 26.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.23.2 in /usr/local/lib/python3.7/dist-packages (from turicreate) (1.3.5)\n",
            "Collecting resampy==0.2.1\n",
            "  Downloading resampy-0.2.1.tar.gz (322 kB)\n",
            "\u001b[K     |████████████████████████████████| 322 kB 42.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.9.1 in /usr/local/lib/python3.7/dist-packages (from turicreate) (2.23.0)\n",
            "Requirement already satisfied: decorator>=4.0.9 in /usr/local/lib/python3.7/dist-packages (from turicreate) (4.4.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from turicreate) (1.4.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from turicreate) (1.15.0)\n",
            "Collecting prettytable==0.7.2\n",
            "  Downloading prettytable-0.7.2.zip (28 kB)\n",
            "Collecting tensorflow<2.1.0,>=2.0.0\n",
            "  Downloading tensorflow-2.0.4-cp37-cp37m-manylinux2010_x86_64.whl (86.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 86.4 MB 73 kB/s \n",
            "\u001b[?25hCollecting coremltools==3.3\n",
            "  Downloading coremltools-3.3-cp37-none-manylinux1_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 29.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from turicreate) (1.21.5)\n",
            "Requirement already satisfied: pillow>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from turicreate) (7.1.2)\n",
            "Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from coremltools==3.3->turicreate) (3.17.3)\n",
            "Collecting llvmlite<0.34,>=0.33.0.dev0\n",
            "  Downloading llvmlite-0.33.0-cp37-cp37m-manylinux1_x86_64.whl (18.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 18.3 MB 457 kB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba<0.51.0->turicreate) (57.4.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.2->turicreate) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.2->turicreate) (2.8.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9.1->turicreate) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9.1->turicreate) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9.1->turicreate) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9.1->turicreate) (2021.10.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (1.1.0)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting tensorboard<2.1.0,>=2.0.0\n",
            "  Downloading tensorboard-2.0.2-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 30.8 MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.1 MB/s \n",
            "\u001b[?25hCollecting h5py<=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 38.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (3.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (1.44.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (0.2.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (1.0.0)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "  Downloading tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449 kB)\n",
            "\u001b[K     |████████████████████████████████| 449 kB 54.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (0.37.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (1.13.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (1.0.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (4.11.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (3.2.0)\n",
            "Building wheels for collected packages: prettytable, resampy, gast\n",
            "  Building wheel for prettytable (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prettytable: filename=prettytable-0.7.2-py3-none-any.whl size=13714 sha256=63a3822b90e10bb613aa1eeecf244def983f71358fe14b2ba56ef5fba2e9efbd\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/7f/f6/f180315b584f00445045ff1699b550fa895d09471337ce21c6\n",
            "  Building wheel for resampy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for resampy: filename=resampy-0.2.1-py3-none-any.whl size=320859 sha256=ef7961369da1a2a098e55c83fcac51c551df48ae521060469229ddad3f3f857d\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/74/53/d5ceb7c5ee7a168c7d106041863e71ac3273f4a4677743a284\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=497ba300e58d7728c9506fbec66821f8f8e7610343d5b86c9d7b211d9962d0c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built prettytable resampy gast\n",
            "Installing collected packages: numpy, llvmlite, h5py, tensorflow-estimator, tensorboard, numba, keras-applications, gast, tensorflow, resampy, prettytable, coremltools, turicreate\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.5\n",
            "    Uninstalling numpy-1.21.5:\n",
            "      Successfully uninstalled numpy-1.21.5\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0\n",
            "    Uninstalling tensorflow-2.8.0:\n",
            "      Successfully uninstalled tensorflow-2.8.0\n",
            "  Attempting uninstall: resampy\n",
            "    Found existing installation: resampy 0.2.2\n",
            "    Uninstalling resampy-0.2.2:\n",
            "      Successfully uninstalled resampy-0.2.2\n",
            "  Attempting uninstall: prettytable\n",
            "    Found existing installation: prettytable 3.2.0\n",
            "    Uninstalling prettytable-3.2.0:\n",
            "      Successfully uninstalled prettytable-3.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.18.5 which is incompatible.\n",
            "librosa 0.8.1 requires resampy>=0.2.2, but you have resampy 0.2.1 which is incompatible.\n",
            "jaxlib 0.3.0+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.18.5 which is incompatible.\n",
            "jax 0.3.1 requires numpy>=1.19, but you have numpy 1.18.5 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed coremltools-3.3 gast-0.2.2 h5py-2.10.0 keras-applications-1.0.8 llvmlite-0.33.0 numba-0.50.1 numpy-1.18.5 prettytable-0.7.2 resampy-0.2.1 tensorboard-2.0.2 tensorflow-2.0.4 tensorflow-estimator-2.0.1 turicreate-6.4.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import linear_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "\n",
        "feature1=[1,1,2,2,3,3,4]\n",
        "feature2=[2,3,3,4,2,5,1]\n",
        "label=[1.03,-1.44,4.53, 2.24, 13.27, 5.62, 21.53]\n",
        "data= [feature1,feature2,label]\n",
        "dataset = pd.DataFrame (data).transpose()\n",
        "dataset.columns = ['feature1', 'feature2', 'label']\n",
        "\n",
        "modelSquare=[]\n",
        "\n",
        "for x in range(len(dataset.columns)):\n",
        "  modelSquare.append(random.randint(-5, 5))\n",
        "modelAbsolute=modelSquare.copy()\n",
        "\n",
        "\n",
        "def evaluate_model(model,point):\n",
        "  resultado=0.0\n",
        "  \n",
        "  for i in range(len(point)-1):\n",
        "    resultado+=point[i]*model[i]\n",
        "  return resultado+model[-1]\n",
        "\n",
        "def errorFunction(model,df):\n",
        "  error=0.0\n",
        "  error_cuadrado=0.0\n",
        "  for i in range(df.shape[0]):\n",
        "    punto=df.iloc[i].to_numpy()\n",
        "    error+=evaluate_model(model,punto)\n",
        "    error_cuadrado=evaluate_model(model,punto)*evaluate_model(model,punto)\n",
        "  print(\"El error absoluto medio es: \", error/df.shape[0])\n",
        "  print(\"El error cuadratico medio es: \", error_cuadrado/df.shape[0])\n",
        "\n",
        "def multipleLinearRegresionSquareTrick(model, point, learning_rate):\n",
        "  \n",
        "  new_b=model[-1]+learning_rate*(point[-1]-evaluate_model(model,point))\n",
        "  model[-1]=new_b\n",
        "  for i in range(len(dataset.columns)-1):\n",
        "    new_w=model[i]+learning_rate*point[i]*(point[-1]-evaluate_model(model,point))\n",
        "    model[i]=new_w\n",
        "\n",
        "def multipleLinearRegresionAbsoluteTrick(model, point, learning_rate):\n",
        "\n",
        "  if point[-1]>evaluate_model(model,point):\n",
        "\n",
        "    new_b=model[-1]+learning_rate\n",
        "    for i in range(len(dataset.columns)-1):\n",
        "      new_w=model[i]+learning_rate*point[i]\n",
        "      model[i]=new_w\n",
        "\n",
        "  else:\n",
        "\n",
        "    new_b=model[-1]-learning_rate\n",
        "    for i in range(len(point)-1):\n",
        "      new_w=model[i]-learning_rate*point[i]\n",
        "      model[i]=new_w\n",
        "\n",
        "  model[-1]=new_b\n",
        " \n",
        "for i in range(0,1000):\n",
        "  punto=dataset.iloc[random.randint(0,dataset.shape[0]-1)].to_numpy()\n",
        "  multipleLinearRegresionSquareTrick(modelSquare,punto,0.05)\n",
        "  multipleLinearRegresionAbsoluteTrick(modelAbsolute,punto,0.05)\n",
        "\n",
        "print(\"Modelo de la implementación Square trick: \",modelSquare)\n",
        "errorFunction(modelSquare,dataset)\n",
        "print(\"\")\n",
        "print(\"Modelo de la implementación Absolute trick: \",modelAbsolute)\n",
        "errorFunction(modelAbsolute,dataset)\n",
        "\n",
        "\n",
        "#Turi Create\n",
        "\n",
        "import turicreate as tc\n",
        "\n",
        "# Load the data\n",
        "data =  tc.SFrame(dataset)\n",
        "\n",
        "# Make a train-test split\n",
        "#train_data, test_data = data.random_split(0.8)\n",
        "\n",
        "# Automatically picks the right model based on your data.\n",
        "model = tc.linear_regression.create(data, target='label',\n",
        "                                    features = ['feature1', 'feature2'], verbose=False)\n",
        "\n",
        "print(model.coefficients)\n",
        "# Save predictions to an SArray\n",
        "#predictions = model.predict(test_data)\n",
        "\n",
        "# Evaluate the model and save the results into a dictionary\n",
        "#results = model.evaluate(test_data)\n",
        "\n",
        "#print(results)\n",
        "\n",
        "#Scikit Learn\n",
        "\n",
        "X= dataset.drop(['label'],axis=1)\n",
        "y = dataset['label']\n",
        "\n",
        "#X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2,random_state=1)\n",
        "\n",
        "\n",
        "regr = linear_model.LinearRegression()\n",
        "regr.fit(X, y)\n",
        "\n",
        "print(\"\")\n",
        "print(\"Modelo SKlearn: \", regr.coef_, regr.intercept_)\n",
        "\n",
        "#y_pred=regr.predict(X_test)\n",
        "#print(\"Linear Regression Accuracy for Scikit-Learn: %f\" % ( metrics.accuracy_score(y_test, y_pred)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8m50B8uzbxF",
        "outputId": "e29851d5-198f-4ecb-ce5f-a0930c18e8cd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo de la implementación Square trick:  [6.02415679668034, -2.503454759285354, 0.04187502108118675]\n",
            "El error absoluto medio es:  6.658648386963809\n",
            "El error cuadratico medio es:  66.86789687137004\n",
            "\n",
            "Modelo de la implementación Absolute trick:  [6.200000000000008, -2.6999999999999917, 0.10000000000000032]\n",
            "El error absoluto medio es:  6.557142857142899\n",
            "El error cuadratico medio es:  70.40571428571455\n",
            "+-------------+-------+---------------------+---------------------+\n",
            "|     name    | index |        value        |        stderr       |\n",
            "+-------------+-------+---------------------+---------------------+\n",
            "| (intercept) |  None | 0.05240794104558599 |  0.193992579593948  |\n",
            "|   feature1  |  None |  5.975723751721802  | 0.05204271620406507 |\n",
            "|   feature2  |  None |  -2.459921780743396 | 0.04304818354787499 |\n",
            "+-------------+-------+---------------------+---------------------+\n",
            "[3 rows x 4 columns]\n",
            "\n",
            "\n",
            "Modelo SKlearn:  [ 6.02426471 -2.47485294] -0.01588235294117979\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Si queremos intentar probar nuestra implementacion con el dataset complejo, da error de overflow\n",
        "\n",
        "#dataset = pd.read_csv(\"/content/drive/MyDrive/Uni/IAA/Hyderabad.csv\",header=0)\n",
        "#dataset=dataset.drop(['Location'],axis=1)\n",
        "#dfaux= dataset[\"Price\"]\n",
        "#dataset=dataset.drop(['Price'],axis=1)\n",
        "#dataset.insert(len(dataset.columns), \"Price\", dfaux)"
      ],
      "metadata": {
        "id": "h4KJyR0fKSQW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}